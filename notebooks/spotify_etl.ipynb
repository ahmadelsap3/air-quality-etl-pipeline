{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b665f091",
   "metadata": {},
   "source": [
    "# Spotify ETL Pipeline\n",
    "\n",
    "This notebook implements an ETL (Extract, Transform, Load) pipeline for Spotify data.\n",
    "\n",
    "- **Extract**: Fetch data from Spotify API\n",
    "- **Transform**: Clean and structure the data using Pandas\n",
    "- **Load**: Insert data into PostgreSQL data warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07895212",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install spotipy pandas psycopg2-binary python-dotenv\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c0560",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Load environment variables for API keys and database credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fda5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Spotify API credentials\n",
    "SPOTIFY_CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "SPOTIFY_CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "\n",
    "# PostgreSQL credentials\n",
    "DB_HOST = os.getenv('DB_HOST', 'localhost')\n",
    "DB_PORT = os.getenv('DB_PORT', '5432')\n",
    "DB_NAME = os.getenv('DB_NAME', 'spotify_dw')\n",
    "DB_USER = os.getenv('DB_USER', 'postgres')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "\n",
    "# Check if credentials are loaded\n",
    "if not SPOTIFY_CLIENT_ID or not SPOTIFY_CLIENT_SECRET:\n",
    "    raise ValueError(\"Spotify API credentials not found. Please set SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET in .env file\")\n",
    "\n",
    "if not DB_PASSWORD:\n",
    "    raise ValueError(\"Database password not found. Please set DB_PASSWORD in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf11d72",
   "metadata": {},
   "source": [
    "## 3. Extract Data from Spotify API\n",
    "\n",
    "Authenticate with Spotify API and extract data for a specific playlist or artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Spotify\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Example: Extract tracks from a playlist\n",
    "# Replace with your playlist ID\n",
    "playlist_id = '37i9dQZF1DXcBWIGoYBM5M'  # Today's Top Hits (example)\n",
    "\n",
    "def extract_playlist_tracks(playlist_id):\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    tracks = []\n",
    "    \n",
    "    while results:\n",
    "        for item in results['items']:\n",
    "            track = item['track']\n",
    "            if track:\n",
    "                track_data = {\n",
    "                    'track_id': track['id'],\n",
    "                    'track_name': track['name'],\n",
    "                    'artist_id': track['artists'][0]['id'] if track['artists'] else None,\n",
    "                    'artist_name': track['artists'][0]['name'] if track['artists'] else None,\n",
    "                    'album_id': track['album']['id'],\n",
    "                    'album_name': track['album']['name'],\n",
    "                    'duration_ms': track['duration_ms'],\n",
    "                    'popularity': track['popularity'],\n",
    "                    'external_urls': track['external_urls']['spotify'],\n",
    "                    'extracted_at': datetime.now().isoformat()\n",
    "                }\n",
    "                tracks.append(track_data)\n",
    "        \n",
    "        # Get next page\n",
    "        results = sp.next(results) if results['next'] else None\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "# Extract data\n",
    "raw_tracks = extract_playlist_tracks(playlist_id)\n",
    "print(f\"Extracted {len(raw_tracks)} tracks\")\n",
    "\n",
    "# Save raw data to JSON for inspection\n",
    "with open('../data/raw_tracks.json', 'w') as f:\n",
    "    json.dump(raw_tracks, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be03c807",
   "metadata": {},
   "source": [
    "## 4. Transform Data\n",
    "\n",
    "Clean and structure the extracted data using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data into DataFrame\n",
    "df_tracks = pd.DataFrame(raw_tracks)\n",
    "\n",
    "# Data cleaning\n",
    "# Remove duplicates\n",
    "df_tracks = df_tracks.drop_duplicates(subset=['track_id'])\n",
    "\n",
    "# Handle missing values\n",
    "df_tracks = df_tracks.dropna(subset=['track_id', 'track_name'])\n",
    "\n",
    "# Convert duration from ms to seconds\n",
    "df_tracks['duration_sec'] = df_tracks['duration_ms'] / 1000\n",
    "df_tracks = df_tracks.drop('duration_ms', axis=1)\n",
    "\n",
    "# Convert extracted_at to datetime\n",
    "df_tracks['extracted_at'] = pd.to_datetime(df_tracks['extracted_at'])\n",
    "\n",
    "# Create separate DataFrames for artists and albums\n",
    "df_artists = df_tracks[['artist_id', 'artist_name']].drop_duplicates().dropna()\n",
    "df_albums = df_tracks[['album_id', 'album_name']].drop_duplicates().dropna()\n",
    "\n",
    "# Keep only necessary columns for tracks\n",
    "df_tracks_clean = df_tracks[['track_id', 'track_name', 'artist_id', 'album_id', 'duration_sec', 'popularity', 'external_urls', 'extracted_at']]\n",
    "\n",
    "print(\"Transformed data shapes:\")\n",
    "print(f\"Tracks: {df_tracks_clean.shape}\")\n",
    "print(f\"Artists: {df_artists.shape}\")\n",
    "print(f\"Albums: {df_albums.shape}\")\n",
    "\n",
    "# Save transformed data\n",
    "df_tracks_clean.to_csv('../data/transformed_tracks.csv', index=False)\n",
    "df_artists.to_csv('../data/transformed_artists.csv', index=False)\n",
    "df_albums.to_csv('../data/transformed_albums.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bbb72",
   "metadata": {},
   "source": [
    "## 5. Load Data to PostgreSQL\n",
    "\n",
    "Connect to PostgreSQL and load the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c038a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    database=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables if they don't exist\n",
    "create_artists_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS artists (\n",
    "    artist_id VARCHAR(50) PRIMARY KEY,\n",
    "    artist_name VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_albums_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS albums (\n",
    "    album_id VARCHAR(50) PRIMARY KEY,\n",
    "    album_name VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_tracks_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS tracks (\n",
    "    track_id VARCHAR(50) PRIMARY KEY,\n",
    "    track_name VARCHAR(255) NOT NULL,\n",
    "    artist_id VARCHAR(50) REFERENCES artists(artist_id),\n",
    "    album_id VARCHAR(50) REFERENCES albums(album_id),\n",
    "    duration_sec FLOAT,\n",
    "    popularity INTEGER,\n",
    "    external_urls VARCHAR(500),\n",
    "    extracted_at TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_artists_table)\n",
    "cursor.execute(create_albums_table)\n",
    "cursor.execute(create_tracks_table)\n",
    "conn.commit()\n",
    "\n",
    "# Load data\n",
    "# Insert artists\n",
    "for _, row in df_artists.iterrows():\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO artists (artist_id, artist_name) VALUES (%s, %s) ON CONFLICT (artist_id) DO NOTHING\",\n",
    "        (row['artist_id'], row['artist_name'])\n",
    "    )\n",
    "\n",
    "# Insert albums\n",
    "for _, row in df_albums.iterrows():\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO albums (album_id, album_name) VALUES (%s, %s) ON CONFLICT (album_id) DO NOTHING\",\n",
    "        (row['album_id'], row['album_name'])\n",
    "    )\n",
    "\n",
    "# Insert tracks\n",
    "for _, row in df_tracks_clean.iterrows():\n",
    "    cursor.execute(\n",
    "        \"\"\"INSERT INTO tracks (track_id, track_name, artist_id, album_id, duration_sec, popularity, external_urls, extracted_at) \n",
    "           VALUES (%s, %s, %s, %s, %s, %s, %s, %s) ON CONFLICT (track_id) DO NOTHING\"\"\",\n",
    "        (row['track_id'], row['track_name'], row['artist_id'], row['album_id'], \n",
    "         row['duration_sec'], row['popularity'], row['external_urls'], row['extracted_at'])\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "print(\"Data loaded successfully\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcd819",
   "metadata": {},
   "source": [
    "## 6. Verification\n",
    "\n",
    "Verify that the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to verify\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    database=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD\n",
    ")\n",
    "\n",
    "# Query sample data\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT COUNT(*) FROM tracks\")\n",
    "track_count = cursor.fetchone()[0]\n",
    "print(f\"Total tracks in database: {track_count}\")\n",
    "\n",
    "cursor.execute(\"SELECT track_name, artist_name, popularity FROM tracks t JOIN artists a ON t.artist_id = a.artist_id ORDER BY popularity DESC LIMIT 5\")\n",
    "top_tracks = cursor.fetchall()\n",
    "print(\"\\nTop 5 tracks by popularity:\")\n",
    "for track in top_tracks:\n",
    "    print(f\"{track[0]} by {track[1]} (Popularity: {track[2]})\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
